{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_Platanos_Calidad\n",
    "Importa las bibliotecas necesarias para el procesamiento de imágenes, la creación y entrenamiento de modelos de redes neuronales, y la gestión de conjuntos de datos.\n",
    "\n",
    "- os: Proporciona funciones para interactuar con el sistema operativo, como manipulación de rutas de archivos y directorios.\n",
    "- cv2: Biblioteca OpenCV para procesamiento de imágenes y visión por computadora.\n",
    "- numpy: Biblioteca para cálculos numéricos eficientes en Python.\n",
    "- torch: Biblioteca principal de PyTorch para cálculos en tensores y operaciones en redes neuronales.\n",
    "- torch.nn: Módulo de PyTorch que proporciona herramientas para la definición y entrenamiento de redes neuronales.\n",
    "- torch.optim: Módulo de PyTorch que contiene implementaciones de varios optimizadores para ajustar los pesos de los modelos.\n",
    "- torch.utils.data: Utilidades para trabajar con conjuntos de datos en PyTorch.\n",
    "- Dataset: Clase base para definir conjuntos de datos personalizados.\n",
    "- DataLoader: Clase que permite cargar datos en lotes y proporciona funcionalidad para el entrenamiento en lotes.\n",
    "- torchvision.transforms.ToTensor: Transforma una imagen PIL o NumPy en un tensor de PyTorch.\n",
    "\n",
    "No se pasan parámetros a estas importaciones, simplemente se importan las bibliotecas necesarias para el código posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir la clase del conjunto de datos personalizado\n",
    "class BananaDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        \"\"\"\n",
    "        Clase personalizada para el conjunto de datos de plátanos de diferentes calidades.\n",
    "\n",
    "        Parámetros:\n",
    "        - root_dir (str): Ruta del directorio raíz que contiene las carpetas de calidad de las imágenes.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.quality_folders = ['excelente', 'regular', 'baja', 'mala']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Recorrer las carpetas de calidad y cargar las imágenes y etiquetas correspondientes\n",
    "        for i, quality in enumerate(self.quality_folders):\n",
    "            folder_path = os.path.join(self.root_dir, quality)\n",
    "            image_files = os.listdir(folder_path)\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(folder_path, image_file)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (512, 512))\n",
    "                self.images.append(image)\n",
    "                self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Retorna la cantidad de imágenes en el conjunto de datos.\n",
    "\n",
    "        Retorna:\n",
    "        - length (int): Cantidad de imágenes en el conjunto de datos.\n",
    "        \"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retorna una imagen y su etiqueta correspondiente en la posición `idx`.\n",
    "\n",
    "        Parámetros:\n",
    "        - idx (int): Índice de la imagen y etiqueta a obtener.\n",
    "\n",
    "        Retorna:\n",
    "        - image (Tensor): Imagen representada como un tensor.\n",
    "        - label (int): Etiqueta de calidad de la imagen.\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return ToTensor()(image), label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una instancia del conjunto de datos personalizado llamado `BananaDataset`, \n",
    "que se utiliza para cargar y gestionar las imágenes de plátanos de diferentes calidades.\n",
    "\n",
    "Parámetros:\n",
    "- 'img' (str): Ruta del directorio raíz que contiene las carpetas de calidad de las imágenes.\n",
    "\n",
    "Retorna:\n",
    "- dataset (BananaDataset): Una instancia del conjunto de datos personalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crear una instancia del conjunto de datos\n",
    "dataset = BananaDataset('img')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "test_size = len(dataset) - train_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide el conjunto de datos en conjuntos de entrenamiento y prueba, con una proporción especificada.\n",
    "\n",
    "Parámetros:\n",
    "- train_ratio (float): Proporción de datos a asignar al conjunto de entrenamiento.\n",
    "- len(dataset) (int): Cantidad total de datos en el conjunto de datos.\n",
    "- train_size (int): Cantidad de datos asignados al conjunto de entrenamiento.\n",
    "- test_size (int): Cantidad de datos asignados al conjunto de prueba.\n",
    "\n",
    "Retorna:\n",
    "- train_set (Subset): Conjunto de datos de entrenamiento.\n",
    "- test_set (Subset): Conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea cargadores de datos para el conjunto de entrenamiento y prueba.\n",
    "\n",
    "Parámetros:\n",
    "- train_set (Subset): Conjunto de datos de entrenamiento.\n",
    "- test_set (Subset): Conjunto de datos de prueba.\n",
    "- batch_size (int): Tamaño del lote (número de muestras por lote).\n",
    "- shuffle (bool): Indica si se deben mezclar los datos en cada época o no.\n",
    "\n",
    "Retorna:\n",
    "- train_loader (DataLoader): Cargador de datos para el conjunto de entrenamiento.\n",
    "- test_loader (DataLoader): Cargador de datos para el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear cargadores de datos para el conjunto de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Clase que define un modelo de red neuronal convolucional (CNN).\n",
    "\n",
    "Atributos:\n",
    "- conv1 (nn.Conv2d): Capa de convolución 2D inicial.\n",
    "- pool (nn.MaxPool2d): Capa de pooling para reducción de dimensionalidad.\n",
    "- conv2 (nn.Conv2d): Capa de convolución 2D adicional.\n",
    "- fc1 (nn.Linear): Capa totalmente conectada (fully connected).\n",
    "- fc2 (nn.Linear): Capa totalmente conectada final que produce las salidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definir el modelo de CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 127 * 127, 64)\n",
    "        self.fc2 = nn.Linear(64, 4)  # 4 clases de calidad en total\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implementación del paso hacia adelante (forward pass) del modelo de CNN.\n",
    "\n",
    "        Parámetros:\n",
    "        - x (Tensor): Datos de entrada (imágenes) representados como un tensor.\n",
    "\n",
    "        Retorna:\n",
    "        - x (Tensor): Salida del modelo.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 127 * 127)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una instancia del modelo de la red neuronal convolucional (CNN, por sus siglas en inglés) denominado `CNN`. \n",
    "Este modelo ha sido diseñado específicamente para el reconocimiento de calidad de plátanos y clasificación en diferentes categorías de calidad.\n",
    "\n",
    "Retorna:\n",
    "- model (CNN): Una instancia del modelo de la red neuronal convolucional para el reconocimiento de calidad de plátanos.\n",
    "\n",
    "\n",
    "Define la función de pérdida utilizada para entrenar el modelo. En este caso, se utiliza la función de pérdida \n",
    "de entropía cruzada (CrossEntropyLoss), que es adecuada para problemas de clasificación multiclase.\n",
    "\n",
    "Retorna:\n",
    "- criterion (CrossEntropyLoss): La función de pérdida de entropía cruzada.\n",
    "\n",
    "\n",
    "Crea el optimizador utilizado para ajustar los pesos del modelo durante el entrenamiento. Se utiliza el algoritmo Adam, \n",
    "que es un método de optimización popular y eficiente para el entrenamiento de redes neuronales.\n",
    "\n",
    "Parámetros:\n",
    "- model.parameters(): Parámetros del modelo que se optimizarán.\n",
    "- lr (float): Tasa de aprendizaje, que determina la velocidad de ajuste de los pesos durante el entrenamiento.\n",
    "\n",
    "Retorna:\n",
    "- optimizer (Adam): El optimizador Adam configurado con los parámetros del modelo y la tasa de aprendizaje especificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Crear una instancia del modelo y definir la función de pérdida y el optimizador\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de épocas, que representa la cantidad de veces que el modelo recorre todo el conjunto de datos de entrenamiento durante el proceso de entrenamiento.\n",
    "\n",
    "Parámetros:\n",
    "- num_epochs (int): Número de épocas para entrenar el modelo.\n",
    "\n",
    "Detecta si una GPU (CUDA) está disponible y configura el dispositivo a utilizar. \n",
    "Si CUDA está disponible, el dispositivo se establece en \"cuda\", de lo contrario, se establece en \"cpu\".\n",
    "\n",
    "Retorna:\n",
    "- device (torch.device): El dispositivo utilizado para el entrenamiento (GPU o CPU).\n",
    "\n",
    "Mueve el modelo a la GPU o la CPU según el dispositivo detectado.\n",
    "\n",
    "Parámetros:\n",
    "- device (torch.device): El dispositivo al que se moverá el modelo (GPU o CPU).\n",
    "\n",
    "Por ultimo: Realiza el bucle de entrenamiento del modelo durante el número de épocas especificado. En cada época, se itera sobre los lotes de datos del conjunto de entrenamiento y se realiza la propagación hacia adelante, el cálculo de la pérdida, la propagación hacia atrás y la actualización de los pesos del modelo.\n",
    "\n",
    "Imprime el valor de pérdida promedio para cada época.\n",
    "\n",
    "No se retornan valores, solo se entrena el modelo y se imprime el progreso del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pone el modelo en modo de evaluación. Esto es necesario para desactivar ciertas capas como la capa de dropout que se utilizan durante el entrenamiento pero no durante la evaluación.\n",
    "\n",
    "No se pasan parámetros y no hay valor de retorno.\n",
    "\n",
    "Variables para realizar un seguimiento del número de \n",
    "predicciones correctas y el número total de imágenes evaluadas.\n",
    "\n",
    "- correct (int): Número de predicciones correctas.\n",
    "- total (int): Número total de imágenes evaluadas.\n",
    "\n",
    "Evalúa el modelo utilizando el conjunto de prueba. Para cada lote de imágenes y etiquetas en el conjunto de prueba, se realizan predicciones utilizando el modelo y se comparan con las etiquetas verdaderas.\n",
    "\n",
    "- images (torch.Tensor): Tensores de imágenes del lote.\n",
    "- labels (torch.Tensor): Tensores de etiquetas del lote.\n",
    "\n",
    "No se retornan valores, las variables correct y total se actualizan con el conteo de predicciones correctas y el número total de imágenes evaluadas.\n",
    "\n",
    "Calcula la precisión del modelo en el conjunto de prueba como un porcentaje.\n",
    "\n",
    "Retorna:\n",
    "- accuracy (float): Precisión del modelo en el conjunto de prueba.\n",
    "\n",
    "Imprime la precisión del modelo en el conjunto de prueba.\n",
    "\n",
    "No se retorna ningún valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "print(f\"Accuracy on test set: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
